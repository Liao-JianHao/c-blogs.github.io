---
layout:     post
title:      数据分析(二)
subtitle:   pandas
date:       2019-08-02
author:     Mr.C
header-img: img/ML.jpg
catalog: true
tags:
    - matplotlib
    - numpy
    - pandas

---



## Pandas

#### Pandas —— 画图

-  pandas.DataFrame.plot
    - `DataFrame.plot(x=None, y=None, kind='line')`：kind绘图类型

-  pandas.Series.plot

    > Series的画图方法和DataFrame只不过是一维，x默认index

    - `Series.plot(kind='line')`
    
![plt_pd](http://www.c-blogs.cn/img/plt_pd.png)

#### Pandas —— 文件读取与存储

> pandas会支持复杂的IO操作，pandas的API支持众多的文件格式，如CSV、SQL、XLS、JSON、HDF5
>> 最常用的HDF5(二进制文件)和CSV文件

- read_csv 读取文件
    - `pandas.read_csv(filepath_or_buffer, sep =',' )`
        - filepath_or_buffer:文件路径
        - usecols:指定读取的列名，列表形式

- to_csv 保存为csv文件
    - `DataFrame.to_csv(path_or_buf=None, sep=', ’, columns=None, header=True, index=True, mode='w', encoding=None)`
        - path_or_buf :string or file handle, default None
        - sep :character, default ‘,’
        - columns :sequence, optional
        - mode:'w'：重写, 'a' 追加
        - index:是否写进行索引
        - header :boolean or list of string, default True,是否写进列索引值

- read_hdf与to_hdf
    
    > HDF5文件的读取和存储需要指定一个键，值为要存储的DataFrame
    >> HDF5在存储时支持压缩，还是跨平台的

    - `pandas.read_hdf(path_or_buf，key =None，** kwargs)`：
    从h5文件当中读取数据
        -path_or_buffer:文件路径
        - key:读取的键，如果只有一个表，可以不用写key
        - return:Theselected object

    - `DataFrame.to_hdf(path_or_buf, key, *\kwargs*)`
        - key：读取的键，保存时需要指定表的名字key
    
    > 需要安装安装tables模块避免不能读取HDF5文件
    
    ~~~python
    pip install tables
    ~~~

- read_json
    - `pandas.read_json(path_or_buf=None, orient=None, typ='frame', lines=False)`
        - 将JSON格式准换成默认的Pandas DataFrame格式
        - orient : string,Indication of expected JSON string format，指定格式
        - lines : boolean, default False，是否按行读
        - typ : default ‘frame’， 指定转换成的对象类型series或者dataframe

- to_json

    > 将Pandas 对象存储为json格式
    
    - `DataFrame.to_json(path_or_buf=None, orient=None, lines=False)`
        - path_or_buf=None：文件地址
        - orient:存储的json形式，{‘split’,’records’,’index’,’columns’,’values’}
        - lines:True按行存，False按一行存
    
#### Pandas —— 缺失值处理

> 步骤： <br> 
1.判断是否有缺失值：np.nan(计算机中是空值)；特殊标记的缺失 <br> 
2.缺失值的处理：删除(整个样本删除)、填充

- 判断数据是否为NaN
    - `pd.isnull()`：判断每个位置的元素是否np.nan

    ~~~python
    import numpy as np
    import pandas as pd
    
    np.any(data.isnull())  # 如果有缺失返回True
    ~~~

    - `pd.notnull()`：判断每个位置的元素是否不是np.nan
    
    ~~~python
    import numpy as np
    import pandas as pd
    
    np.all(data.notnull())  # 如果有缺失返回False
    ~~~

    - 处理缺失值
    
    ~~~python
    # 第一种方式：删除
    data.dropna()  # 删除缺失的行，返回新的数据集
    
    # 第二种方式：填充
    data.fillna(填充缺失)  # 比如使用data.mean()
    
    # 第三种方式：特殊缺失值
    data.replace(to_replace='需要替换的值', value=np.nan)
    ~~~

#### Pandas —— 数据离散化

> 连续属性的离散化就是在连续属性的值域上，将值域划分为若干个离散的区间，最后用不同的符号或整数 值代表落在每个子区间中的属性值
>> 数据离散化技术可以用来减少给定连续属性值的个数。离散化方法经常作为数据挖掘的工具 <br> 
 <br> 
两种方法： <br> 
1.区间平均分，给每个样本打标签 <br> 
2.把每个类别的数量平均分，再定区间(可能区间跨度大)

- 把样本进行平均分：`pd.qcut(data, num, labels=['A', 'B'])`
    - 传入需要离散的数据；传入分为几个区间，可以给区间起别名


- 把区间进行平均分：`pd.cut(data,bins=bins)`
    - `bins`：可自定义区间分组

- one-hot编码
    
    > 把每个类别生成一个布尔列，这些列中只有一列可以为这个样本取值为1.其又被称为热编码

    - pandas.get_dummies(data, prefix=None)
        - data:array-like, Series, or DataFrame
        - prefix:分组名字

#### Pandas —— 数据合并

> 数据由多张表组成，那么有时候需要将不同的内容合并在一起分析
>> 左连接、右连接、内连接、外连接

- `pd.concat([data1, data2], axis=1)`
    - 按照行或列进行合并,axis=0为列索引，axis=1为行索引

- `pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None)`

    > 可以指定按照两组数据的共同键值对合并或者左右各值

    - left: A DataFrame object
    - right: Another DataFrame object
    - on: Columns (names) to join on. Must be found in both the left and right DataFrame objects，按照公有值合并
    - left_on=None, right_on=None：指定左右键

#### Pandas —— 分组与聚合

> 分组与聚合通常是分析数据的一种方式，通常与一些统计函数一起使用，查看数据的分组情况

- `DataFrame.groupby(key, as_index=False)`
    - key:分组的列数据，可以多个
    
    ~~~python
    import pandas as pd
    
    
    data.groupby('分组')  # 此时返回的是一个 DataFrameGourpBy 对象

    data.groupby('分组').聚合操作()  # 需要做聚合操作才会返回数据
    ~~~

#### Pandas —— 交叉表与透视表

> 两列离散的数据构建交叉表
>> 交叉表与透视表:所做的事就是分组聚合

- 使用`pivot_table()`(透视表)实现，过程更加简单
    
    ~~~python
    import pandas as pd

    pd.pivot_table(data=data, index=index, columns=columns, values='指定分组的元素', aggfunc='指定聚合的方法')
    ~~~


**注：原创文章，转载请注明出处**
